{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.stats import norm, binomtest\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "\n",
    "class Smooth(object):\n",
    "    \"\"\"A smoothed classifier g \"\"\"\n",
    "\n",
    "    # to abstain, Smooth returns this int\n",
    "    ABSTAIN = -1\n",
    "\n",
    "    def __init__(self, base_classifier: torch.nn.Module, num_classes: int, sigma: float):\n",
    "        \"\"\"\n",
    "        :param base_classifier: maps from [batch x channel x height x width] to [batch x num_classes]\n",
    "        :param num_classes:\n",
    "        :param sigma: the noise level hyperparameter\n",
    "        \"\"\"\n",
    "        self.base_classifier = base_classifier\n",
    "        self.num_classes = num_classes\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def certify(self, x: torch.tensor, n0: int, n: int, alpha: float, batch_size: int) -> (int, float):\n",
    "        \"\"\" Monte Carlo algorithm for certifying that g's prediction around x is constant within some L2 radius.\n",
    "        With probability at least 1 - alpha, the class returned by this method will equal g(x), and g's prediction will\n",
    "        robust within a L2 ball of radius R around x.\n",
    "\n",
    "        :param x: the input [channel x height x width]\n",
    "        :param n0: the number of Monte Carlo samples to use for selection\n",
    "        :param n: the number of Monte Carlo samples to use for estimation\n",
    "        :param alpha: the failure probability\n",
    "        :param batch_size: batch size to use when evaluating the base classifier\n",
    "        :return: (predicted class, certified radius)\n",
    "                 in the case of abstention, the class will be ABSTAIN and the radius 0.\n",
    "        \"\"\"\n",
    "        self.base_classifier.eval()\n",
    "        # draw samples of f(x+ epsilon)\n",
    "        counts_selection = self._sample_noise(x, n0, batch_size)\n",
    "        # use these samples to take a guess at the top class\n",
    "        cAHat = counts_selection.argmax().item()\n",
    "        # draw more samples of f(x + epsilon)\n",
    "        counts_estimation = self._sample_noise(x, n, batch_size)\n",
    "        # use these samples to estimate a lower bound on pA\n",
    "        nA = counts_estimation[cAHat].item()\n",
    "        pABar = self._lower_confidence_bound(nA, n, alpha)\n",
    "        if pABar < 0.5:\n",
    "            return Smooth.ABSTAIN, 0.0\n",
    "        else:\n",
    "            radius = self.sigma * norm.ppf(pABar)\n",
    "            return cAHat, radius\n",
    "\n",
    "    def predict(self, x: torch.tensor, n: int, alpha: float, batch_size: int) -> int:\n",
    "        \"\"\" Monte Carlo algorithm for evaluating the prediction of g at x.  With probability at least 1 - alpha, the\n",
    "        class returned by this method will equal g(x).\n",
    "\n",
    "        This function uses the hypothesis test described in https://arxiv.org/abs/1610.03944\n",
    "        for identifying the top category of a multinomial distribution.\n",
    "\n",
    "        :param x: the input [channel x height x width]\n",
    "        :param n: the number of Monte Carlo samples to use\n",
    "        :param alpha: the failure probability\n",
    "        :param batch_size: batch size to use when evaluating the base classifier\n",
    "        :return: the predicted class, or ABSTAIN\n",
    "        \"\"\"\n",
    "        self.base_classifier.eval()\n",
    "        counts = self._sample_noise(x, n, batch_size)\n",
    "        top2 = counts.argsort()[::-1][:2]\n",
    "        count1 = counts[top2[0]]\n",
    "        count2 = counts[top2[1]]\n",
    "        if binomtest(count1, count1 + count2, p=0.5).pvalue > alpha:\n",
    "            return Smooth.ABSTAIN\n",
    "        else:\n",
    "            return top2[0]\n",
    "\n",
    "    def _sample_noise(self, x: torch.tensor, num: int, batch_size) -> np.ndarray:\n",
    "        \"\"\" Sample the base classifier's prediction under noisy corruptions of the input x.\n",
    "\n",
    "        :param x: the input [channel x width x height]\n",
    "        :param num: number of samples to collect\n",
    "        :param batch_size:\n",
    "        :return: an ndarray[int] of length num_classes containing the per-class counts\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            counts = np.zeros(self.num_classes, dtype=int)\n",
    "            for _ in range(ceil(num / batch_size)):\n",
    "                \n",
    "                # print(_)\n",
    "\n",
    "                this_batch_size = min(batch_size, num)\n",
    "                num -= this_batch_size\n",
    "\n",
    "                batch = x.repeat((this_batch_size, 1, 1, 1))\n",
    "                noise = torch.randn_like(batch, device='cuda') * self.sigma\n",
    "                predictions = self.base_classifier(batch + noise).argmax(1)\n",
    "                counts += self._count_arr(predictions.cpu().numpy(), self.num_classes)\n",
    "            return counts\n",
    "\n",
    "    def _count_arr(self, arr: np.ndarray, length: int) -> np.ndarray:\n",
    "        counts = np.zeros(length, dtype=int)\n",
    "        for idx in arr:\n",
    "            counts[idx] += 1\n",
    "        return counts\n",
    "\n",
    "    def _lower_confidence_bound(self, NA: int, N: int, alpha: float) -> float:\n",
    "        \"\"\" Returns a (1 - alpha) lower confidence bound on a bernoulli proportion.\n",
    "\n",
    "        This function uses the Clopper-Pearson method.\n",
    "\n",
    "        :param NA: the number of \"successes\"\n",
    "        :param N: the number of total draws\n",
    "        :param alpha: the confidence level\n",
    "        :return: a lower bound on the binomial proportion which holds true w.p at least (1 - alpha) over the samples\n",
    "        \"\"\"\n",
    "        return proportion_confint(NA, N, alpha=2 * alpha, method=\"beta\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n",
      "Files already downloaded and verified\n",
      "the size of test set is (1000, 32, 32, 3)\n",
      "the size of test label is (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ducphuc001\\AppData\\Local\\miniconda3\\envs\\smooth\\Lib\\site-packages\\torchvision\\transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m before_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# make the prediction\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43msmoothed_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m after_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m     71\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(prediction \u001b[38;5;241m==\u001b[39m label)\n",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m, in \u001b[0;36mSmooth.predict\u001b[1;34m(self, x, n, alpha, batch_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Monte Carlo algorithm for evaluating the prediction of g at x.  With probability at least 1 - alpha, the\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mclass returned by this method will equal g(x).\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m:return: the predicted class, or ABSTAIN\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_classifier\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 67\u001b[0m counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m top2 \u001b[38;5;241m=\u001b[39m counts\u001b[38;5;241m.\u001b[39margsort()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     69\u001b[0m count1 \u001b[38;5;241m=\u001b[39m counts[top2[\u001b[38;5;241m0\u001b[39m]]\n",
      "Cell \u001b[1;32mIn[1], line 96\u001b[0m, in \u001b[0;36mSmooth._sample_noise\u001b[1;34m(self, x, num, batch_size)\u001b[0m\n\u001b[0;32m     94\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(batch, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma\n\u001b[0;32m     95\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_classifier(batch \u001b[38;5;241m+\u001b[39m noise)\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m     counts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_arr(\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m counts\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# evaluate a smoothed classifier on a dataset\n",
    "import os\n",
    "import setGPU\n",
    "from time import time\n",
    "import torch\n",
    "import datetime\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from iCIFAR100 import iCIFAR100\n",
    "from myNetwork import network\n",
    "from ResNet import resnet18_cbam\n",
    "\n",
    "\n",
    "classes=[10, 20]\n",
    "sigma = 0.25\n",
    "outfile = \"predict/a_model2_1019.txt\"\n",
    "batch = 100\n",
    "skip = 1\n",
    "max = -1\n",
    "N0 = 100\n",
    "N = 1000\n",
    "alpha = 0.001\n",
    "\n",
    "feature_extractor=resnet18_cbam()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    numclass=20\n",
    "\n",
    "    # load the base classifier\n",
    "    # base_classifier = network(numclass,feature_extractor).to(device)\n",
    "    base_classifier = torch.load('model/accuracy_73.900_KNN_accuracy_76.050_increment_29_net.pt').to(device)\n",
    "\n",
    "    # load the dataset\n",
    "    test_transform = transforms.Compose([#transforms.Resize(img_size),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "    dataset = iCIFAR100('dataset', train=False, transform=test_transform, download=True)\n",
    "    dataset.getTestData(classes)\n",
    "    dataset = DataLoader(dataset=dataset,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=1)\n",
    "\n",
    "    # create the smooothed classifier g\n",
    "    smoothed_classifier = Smooth(base_classifier, numclass, sigma)\n",
    "\n",
    "    # prepare output file\n",
    "    f = open(outfile, 'w')\n",
    "    print(\"idx\\tlabel\\tpredict\\tcorrect\\ttime\", file=f, flush=True)\n",
    "    res = []\n",
    "\n",
    "    # iterate through the dataset\n",
    "    for i, (indexs, imgs, labels) in enumerate(dataset):\n",
    "\n",
    "        # only certify every args.skip examples, and stop after args.max examples\n",
    "        if i % skip != 0:\n",
    "            continue\n",
    "        if i == max:\n",
    "            break\n",
    "\n",
    "        (x, label) = (imgs, labels)\n",
    "        x = x.cuda()\n",
    "        before_time = time()\n",
    "\n",
    "        # make the prediction\n",
    "        prediction = smoothed_classifier.predict(x, N, alpha, batch)\n",
    "        after_time = time()\n",
    "        correct = int(prediction == label)\n",
    "\n",
    "        res.append([prediction, label])\n",
    "\n",
    "        time_elapsed = str(datetime.timedelta(seconds=(after_time - before_time)))\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(i, label, prediction, correct, time_elapsed), file=f, flush=True)\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([269])\n",
      "539\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "total = 0\n",
    "for pred, label in res:\n",
    "    accuracy += (pred == label)\n",
    "    total += 1\n",
    "\n",
    "print(accuracy)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smooth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
