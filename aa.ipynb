{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.datasets import CIFAR100\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam',\n",
    "           'resnet152_cbam']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('输入的shape为:'+str(x.shape))\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        #print('avg_out的shape为:' + str(avg_out.shape))\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        #print('max_out的shape为:' + str(max_out.shape))\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        #out = self.ca(out) * out\n",
    "        #out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.ca = ChannelAttention(planes * 4)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=100):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.feature = nn.AvgPool2d(4, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.feature(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #y=torch.norm(x,p=2,dim=1,keepdim=True)\n",
    "        #x/=y\n",
    "        #x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet18'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet34'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet50'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet101'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = model_zoo.load_url(model_urls['resnet152'])\n",
    "        now_state_dict        = model.state_dict()\n",
    "        now_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(now_state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class iCIFAR100(CIFAR100):\n",
    "    def __init__(self,root,\n",
    "                 train=True,\n",
    "                 transform=None,\n",
    "                 target_transform=None,\n",
    "                 download=False):\n",
    "        super(iCIFAR100,self).__init__(root,\n",
    "                                       train=train,\n",
    "                                       transform=transform,\n",
    "                                       target_transform=target_transform,\n",
    "                                       download=download)\n",
    "\n",
    "        self.transform=transform\n",
    "        self.target_transform=target_transform\n",
    "        self.TrainData = []\n",
    "        self.TrainLabels = []\n",
    "        self.TestData = []\n",
    "        self.TestLabels = []\n",
    "        self.train = train\n",
    "\n",
    "    def concatenate(self,datas,labels):\n",
    "        con_data=datas[0]\n",
    "        con_label=labels[0]\n",
    "        for i in range(1,len(datas)):\n",
    "            con_data=np.concatenate((con_data,datas[i]),axis=0)\n",
    "            con_label=np.concatenate((con_label,labels[i]),axis=0)\n",
    "        return con_data,con_label\n",
    "\n",
    "    def getTestData(self, classes):\n",
    "        datas,labels=[],[]\n",
    "        for label in range(classes[0], classes[1]):\n",
    "            data = self.test_data[np.array(self.test_labels) == label]\n",
    "            data = np.transpose(data, (0, 2, 3, 1))\n",
    "            datas.append(data)\n",
    "            labels.append(np.full((data.shape[0]), label))\n",
    "        datas,labels=self.concatenate(datas,labels)\n",
    "        print(f\"Line 37 {datas.shape}\")\n",
    "        print(f\"Line 38 {len(self.TestData)}\")\n",
    "        self.TestData=datas if not len(self.TestData) else np.concatenate((self.TestData,datas),axis=0)\n",
    "        self.TestLabels=labels if not len(self.TestLabels) else np.concatenate((self.TestLabels,labels),axis=0)\n",
    "        \n",
    "        print(\"the size of test set is %s\"%(str(self.TestData.shape)))\n",
    "        print(\"the size of test label is %s\"%str(self.TestLabels.shape))\n",
    "\n",
    "\n",
    "    def getTrainData(self,classes,exemplar_set):\n",
    "\n",
    "        datas,labels=[],[]\n",
    "        if len(exemplar_set)!=0:\n",
    "            datas=[exemplar for exemplar in exemplar_set ]\n",
    "            length=len(datas[0])\n",
    "            labels=[np.full((length),label) for label in range(len(exemplar_set))]\n",
    "\n",
    "        for label in range(classes[0],classes[1]):\n",
    "            data=self.train_data[np.array(self.train_labels)==label]\n",
    "            data = np.transpose(data, (0, 2, 3, 1))\n",
    "            datas.append(data)\n",
    "            labels.append(np.full((data.shape[0]),label))\n",
    "        self.TrainData,self.TrainLabels=self.concatenate(datas,labels)\n",
    "\n",
    "        print(\"the size of train set is %s\"%(str(self.TrainData.shape)))\n",
    "        print(\"the size of train label is %s\"%str(self.TrainLabels.shape))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img  = Image.fromarray(self.TrainData[index]) \n",
    "            target = self.TrainLabels[index]\n",
    "        else:\n",
    "            img, target = Image.fromarray(self.TestData[index]), self.TestLabels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return index, img, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.TrainData)\n",
    "        else:\n",
    "            return len(self.TestData)\n",
    "\n",
    "    def get_image_class(self,label):\n",
    "        res = self.train_data[np.array(self.train_labels)==label]\n",
    "        res = np.transpose(res, (0, 2, 3, 1))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "\n",
    "    def __init__(self, numclass, feature_extractor):\n",
    "        super(network, self).__init__()\n",
    "        self.feature = feature_extractor\n",
    "        self.fc = nn.Linear(feature_extractor.fc.in_features, numclass, bias=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.feature(input)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def Incremental_learning(self, numclass):\n",
    "        weight = self.fc.weight.data\n",
    "        bias = self.fc.bias.data\n",
    "        in_feature = self.fc.in_features\n",
    "        out_feature = self.fc.out_features\n",
    "\n",
    "        self.fc = nn.Linear(in_feature, numclass, bias=True)\n",
    "        self.fc.weight.data[:out_feature] = weight\n",
    "        self.fc.bias.data[:out_feature] = bias\n",
    "\n",
    "    def feature_extractor(self,inputs):\n",
    "        return self.feature(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_one_hot(target,num_class):\n",
    "    one_hot=torch.zeros(target.shape[0],num_class).to(device)\n",
    "    one_hot=one_hot.scatter(dim=1,index=target.long().view(-1,1),value=1.)\n",
    "    return one_hot\n",
    "\n",
    "class iCaRLmodel:\n",
    "\n",
    "    def __init__(self,numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate):\n",
    "\n",
    "        super(iCaRLmodel, self).__init__()\n",
    "        self.epochs=epochs\n",
    "        self.learning_rate=learning_rate\n",
    "        self.model = network(numclass,feature_extractor)\n",
    "        self.exemplar_set = []\n",
    "        self.class_mean_set = []\n",
    "        self.numclass = numclass\n",
    "        self.transform = transforms.Compose([#transforms.Resize(img_size),\n",
    "                                             transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "        self.old_model = None\n",
    "\n",
    "        self.train_transform = transforms.Compose([#transforms.Resize(img_size),\n",
    "                                                  transforms.RandomCrop((32,32),padding=4),\n",
    "                                                  transforms.RandomHorizontalFlip(),\n",
    "                                                #   transforms.ColorJitter(brightness=0.24705882352941178),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "        \n",
    "        self.test_transform = transforms.Compose([#transforms.Resize(img_size),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "        \n",
    "        self.classify_transform=transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                                    #transforms.Resize(img_size),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))])\n",
    "        \n",
    "        self.train_dataset = iCIFAR100('dataset', transform=self.train_transform, download=True)\n",
    "        self.test_dataset = iCIFAR100('dataset', train=False, transform=self.test_transform, download=True)\n",
    "\n",
    "        self.batchsize = batch_size\n",
    "        self.memory_size=memory_size\n",
    "        self.task_size=task_size\n",
    "\n",
    "        self.train_loader=None\n",
    "        self.test_loader=None\n",
    "\n",
    "    # get incremental train data\n",
    "    # incremental\n",
    "    def beforeTrain(self):\n",
    "        self.model.eval()\n",
    "        classes=[self.numclass-self.task_size,self.numclass]\n",
    "        self.train_loader,self.test_loader=self._get_train_and_test_dataloader(classes)\n",
    "        if self.numclass>self.task_size:\n",
    "            self.model.Incremental_learning(self.numclass)\n",
    "        self.model.train()\n",
    "        self.model.to(device)\n",
    "\n",
    "    def _get_train_and_test_dataloader(self, classes):\n",
    "        self.train_dataset.getTrainData(classes, self.exemplar_set)\n",
    "        self.test_dataset.getTestData(classes)\n",
    "\n",
    "        train_loader = DataLoader(dataset=self.train_dataset,\n",
    "                                  shuffle=True,\n",
    "                                  batch_size=self.batchsize)\n",
    "\n",
    "        test_loader = DataLoader(dataset=self.test_dataset,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=self.batchsize)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    '''\n",
    "    def _get_old_model_output(self, dataloader):\n",
    "        x = {}\n",
    "        for step, (indexs, imgs, labels) in enumerate(dataloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                old_model_output = torch.sigmoid(self.old_model(imgs))\n",
    "            for i in range(len(indexs)):\n",
    "                x[indexs[i].item()] = old_model_output[i].cpu().numpy()\n",
    "        return x\n",
    "    '''\n",
    "\n",
    "    # train model\n",
    "    # compute loss\n",
    "    # evaluate model\n",
    "    def train(self):\n",
    "        accuracy = 0\n",
    "        opt = optim.SGD(self.model.parameters(), lr=self.learning_rate, weight_decay=0.00001)\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch == 48:\n",
    "                if self.numclass==self.task_size:\n",
    "                     print(1)\n",
    "                     opt = optim.SGD(self.model.parameters(), lr=1.0/5, weight_decay=0.00001)\n",
    "                else:\n",
    "                     for p in opt.param_groups:\n",
    "                         p['lr'] =self.learning_rate/ 5\n",
    "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate/ 5,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
    "                print(\"change learning rate:%.3f\" % (self.learning_rate / 5))\n",
    "            elif epoch == 62:\n",
    "                if self.numclass>self.task_size:\n",
    "                     for p in opt.param_groups:\n",
    "                         p['lr'] =self.learning_rate/ 25\n",
    "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate/ 25,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
    "                else:\n",
    "                     opt = optim.SGD(self.model.parameters(), lr=1.0/25, weight_decay=0.00001)\n",
    "                print(\"change learning rate:%.3f\" % (self.learning_rate / 25))\n",
    "            elif epoch == 80:\n",
    "                  if self.numclass==self.task_size:\n",
    "                     opt = optim.SGD(self.model.parameters(), lr=1.0 / 125,weight_decay=0.00001)\n",
    "                  else:\n",
    "                     for p in opt.param_groups:\n",
    "                         p['lr'] =self.learning_rate/ 125\n",
    "                     #opt = optim.SGD(self.model.parameters(), lr=self.learning_rate / 125,weight_decay=0.00001,momentum=0.9,nesterov=True,)\n",
    "                  print(\"change learning rate:%.3f\" % (self.learning_rate / 100))\n",
    "            \n",
    "            train_bar = tqdm(self.train_loader, total=len(self.train_loader))\n",
    "            for step, (indexs, images, target) in enumerate(train_bar):\n",
    "                images, target = images.to(device), target.to(device)\n",
    "                #output = self.model(images)\n",
    "                loss_value = self._compute_loss(indexs, images, target)\n",
    "                opt.zero_grad()\n",
    "                loss_value.backward()\n",
    "                opt.step()\n",
    "                # print('epoch:%d,step:%d,loss:%.3f' % (epoch, step, loss_value.item()))\n",
    "                train_bar.set_description(\n",
    "                    desc=\"[%d/%d] Loss: %f  Step: %d  LR: %f\"\n",
    "                    % (\n",
    "                        epoch,\n",
    "                        self.epochs,\n",
    "                        loss_value.item(),\n",
    "                        step,\n",
    "                        opt.param_groups[0]['lr']\n",
    "                    )\n",
    "                )\n",
    "                break\n",
    "            accuracy = self._test(self.test_loader, 1)\n",
    "            print('epoch:%d,accuracy:%.3f' % (epoch, accuracy))\n",
    "        return accuracy\n",
    "\n",
    "    def _test(self, testloader, mode):\n",
    "        if mode==0:\n",
    "            print(\"compute NMS\")\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "        for setp, (indexs, imgs, labels) in enumerate(testloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(imgs) if mode == 1 else self.classify(imgs)\n",
    "            predicts = torch.max(outputs, dim=1)[1] if mode == 1 else outputs\n",
    "            correct += (predicts.cpu() == labels.cpu()).sum()\n",
    "            total += len(labels)\n",
    "        accuracy = 100 * correct / total\n",
    "        self.model.train()\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "    def _compute_loss(self, indexs, imgs, target):\n",
    "        output=self.model(imgs)\n",
    "        target = get_one_hot(target, self.numclass)\n",
    "        output, target = output.to(device), target.to(device)\n",
    "        if self.old_model == None:\n",
    "            return F.binary_cross_entropy_with_logits(output, target)\n",
    "        else:\n",
    "            #old_target = torch.tensor(np.array([self.old_model_output[index.item()] for index in indexs]))\n",
    "            old_target=torch.sigmoid(self.old_model(imgs))\n",
    "            old_task_size = old_target.shape[1]\n",
    "            target[..., :old_task_size] = old_target\n",
    "            return F.binary_cross_entropy_with_logits(output, target)\n",
    "\n",
    "\n",
    "    # change the size of examplar\n",
    "    def afterTrain(self,accuracy):\n",
    "        self.model.eval()\n",
    "        m=int(self.memory_size/self.numclass)\n",
    "        self._reduce_exemplar_sets(m)\n",
    "        for i in range(self.numclass-self.task_size,self.numclass):\n",
    "            print('construct class %s examplar:'%(i),end='')\n",
    "            images=self.train_dataset.get_image_class(i)\n",
    "            self._construct_exemplar_set(images,m)\n",
    "        self.numclass+=self.task_size\n",
    "        self.compute_exemplar_class_mean()\n",
    "        self.model.train()\n",
    "        KNN_accuracy=self._test(self.test_loader,0)\n",
    "        print(\"NMS accuracy：\"+str(KNN_accuracy.item()))\n",
    "        filename='./model/accuracy_%.3f_KNN_accuracy_%.3f_increment_%d_net.pt' % (accuracy, KNN_accuracy, i + 10)\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        torch.save(self.model,filename)\n",
    "        self.old_model=torch.load(filename)\n",
    "        self.old_model.to(device)\n",
    "        self.old_model.eval()\n",
    "        \n",
    "\n",
    "\n",
    "    def _construct_exemplar_set(self, images, m):\n",
    "        class_mean, feature_extractor_output = self.compute_class_mean(images, self.transform)\n",
    "        exemplar = []\n",
    "        now_class_mean = np.zeros((1, 512))\n",
    "     \n",
    "        for i in range(m):\n",
    "            # shape：batch_size*512\n",
    "            x = class_mean - (now_class_mean + feature_extractor_output) / (i + 1)\n",
    "            # shape：batch_size\n",
    "            x = np.linalg.norm(x, axis=1)\n",
    "            index = np.argmin(x)\n",
    "            now_class_mean += feature_extractor_output[index]\n",
    "            exemplar.append(images[index])\n",
    "\n",
    "        print(\"the size of exemplar :%s\" % (str(len(exemplar))))\n",
    "        self.exemplar_set.append(exemplar)\n",
    "        #self.exemplar_set.append(images)\n",
    "\n",
    "    def _reduce_exemplar_sets(self, m):\n",
    "        for index in range(len(self.exemplar_set)):\n",
    "            self.exemplar_set[index] = self.exemplar_set[index][:m]\n",
    "            print('Size of class %d examplar: %s' % (index, str(len(self.exemplar_set[index]))))\n",
    "\n",
    "\n",
    "\n",
    "    def Image_transform(self, images, transform):\n",
    "        data = transform(Image.fromarray(images[0])).unsqueeze(0)\n",
    "        for index in range(1, len(images)):\n",
    "            data = torch.cat((data, self.transform(Image.fromarray(images[index])).unsqueeze(0)), dim=0)\n",
    "        return data\n",
    "\n",
    "    def compute_class_mean(self, images, transform):\n",
    "        x = self.Image_transform(images, transform).to(device)\n",
    "        feature_extractor_output = F.normalize(self.model.feature_extractor(x).detach()).cpu().numpy()\n",
    "        #feature_extractor_output = self.model.feature_extractor(x).detach().cpu().numpy()\n",
    "        class_mean = np.mean(feature_extractor_output, axis=0)\n",
    "        return class_mean, feature_extractor_output\n",
    "\n",
    "\n",
    "    def compute_exemplar_class_mean(self):\n",
    "        self.class_mean_set = []\n",
    "        for index in range(len(self.exemplar_set)):\n",
    "            print(\"compute the class mean of %s\"%(str(index)))\n",
    "            exemplar=self.exemplar_set[index]\n",
    "            #exemplar=self.train_dataset.get_image_class(index)\n",
    "            class_mean, _ = self.compute_class_mean(exemplar, self.transform)\n",
    "            class_mean_,_=self.compute_class_mean(exemplar,self.classify_transform)\n",
    "            class_mean=(class_mean/np.linalg.norm(class_mean)+class_mean_/np.linalg.norm(class_mean_))/2\n",
    "            self.class_mean_set.append(class_mean)\n",
    "\n",
    "    def classify(self, test):\n",
    "        result = []\n",
    "        test = F.normalize(self.model.feature_extractor(test).detach()).cpu().numpy()\n",
    "        #test = self.model.feature_extractor(test).detach().cpu().numpy()\n",
    "        class_mean_set = np.array(self.class_mean_set)\n",
    "        for target in test:\n",
    "            x = target - class_mean_set\n",
    "            x = np.linalg.norm(x, ord=2, axis=1)\n",
    "            x = np.argmin(x)\n",
    "            result.append(x)\n",
    "        return torch.tensor(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "the size of train set is (5000, 32, 32, 3)\n",
      "the size of train label is (5000,)\n",
      "Line 37 (1000, 32, 32, 3)\n",
      "Line 38 0\n",
      "the size of test set is (1000, 32, 32, 3)\n",
      "the size of test label is (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]c:\\Users\\ducphuc001\\AppData\\Local\\miniconda3\\envs\\icarl\\Lib\\site-packages\\torchvision\\transforms.py:36: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "[0/100] Loss: 0.666617  Step: 0  LR: 2.000000:   0%|          | 0/40 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mbeforeTrain()\n\u001b[1;32m---> 15\u001b[0m     accuracy\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mafterTrain(accuracy)\n",
      "Cell \u001b[1;32mIn[5], line 140\u001b[0m, in \u001b[0;36miCaRLmodel.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m         train_bar\u001b[38;5;241m.\u001b[39mset_description(\n\u001b[0;32m    130\u001b[0m             desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m  Step: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m  LR: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m             \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m             )\n\u001b[0;32m    138\u001b[0m         )\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m,accuracy:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, accuracy))\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "Cell \u001b[1;32mIn[5], line 154\u001b[0m, in \u001b[0;36miCaRLmodel._test\u001b[1;34m(self, testloader, mode)\u001b[0m\n\u001b[0;32m    152\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(imgs) \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassify(imgs)\n\u001b[0;32m    153\u001b[0m     predicts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m outputs\n\u001b[1;32m--> 154\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mpredicts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    155\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[0;32m    156\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "numclass=10\n",
    "feature_extractor=resnet18_cbam()\n",
    "img_size=32\n",
    "batch_size=128\n",
    "task_size=10\n",
    "memory_size=2000\n",
    "epochs=100\n",
    "learning_rate=2.0\n",
    "\n",
    "model=iCaRLmodel(numclass,feature_extractor,batch_size,task_size,memory_size,epochs,learning_rate)\n",
    "#model.model.load_state_dict(torch.load('model/ownTry_accuracy:84.000_KNN_accuracy:84.000_increment:10_net.pkl'))\n",
    "\n",
    "for i in range(10):\n",
    "    model.beforeTrain()\n",
    "    accuracy=model.train()\n",
    "    model.afterTrain(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_results = {\n",
    "        \"batch_sizes\": [0],\n",
    "        \"d_loss\": 0,\n",
    "        \"g_loss\": 0,\n",
    "        \"learning_rate\": 0.1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "tmp = []\n",
    "print(tmp == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
